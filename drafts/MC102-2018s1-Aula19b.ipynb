{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T01:12:04.093689Z",
     "start_time": "2018-04-26T01:12:04.090231Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expressões Regulares\n",
    "**MC102-2018s1-Aula19**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma expressão regular (também chamada *RE*, *regex*, ou *regex pattern*) é usada para identificar se um padrão ocorre ou não em uma determinada sequência de caracteres (*string*).\n",
    "\n",
    "Expressões regulares implementam uma forma muito eficiente de manipulação de textos, permitindo o reconhecimento de padrões, a criação de variantes de uma dada *string* e o seu “fatiamento” de diversas maneiras.\n",
    "\n",
    "Dadas as limitações das expressões regulares, elas não serão suficientes para resolver qualquer tarefa de processamento de textos, nem mesmo de expressar de forma simples algumas tarefas possíveis.   \n",
    "Nesses casos, a melhor opção talvez seja desenvolver uma função em Python. Embora o código Python possa ser mais lento que uma expressão regular, ele provavelmente será mais inteligível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em Python, expressões regulares são implementadas pelos módulos ```re``` e ```regex```.   \n",
    "Assim, para poder usá-las em nossos *scripts*, teremos que importar um desses módulos.   \n",
    "Aqui vamos estudar apenas algumas das funcionalidades disponíveis no módulo ```re```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nossos primeiros testes, vamos adotar uma variante de um pangrama famoso..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = '''Then, 80% of the quick brown foxes \n",
    "jumped over the lazy dog.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... que gera a seguinte cadeia:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`0........10........20........30........40........50........60`   \n",
    "`Then, 80% of the quick brown foxes *jumped over the lazy dog.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em Python, a busca de uma expressão regular num dado texto é normalmente feita por..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(13, 16), match='the'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'the', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match(r'the', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que ```match``` aparentemente não produziu resultado algum.    \n",
    "Na verdade, o resultado foi `None`, que não é exibido nesse formato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(re.match(r'berro', t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferença entre essas duas funções é que ```match``` verifica se a expressão regular ocorre logo no início do texto, enquanto ```search``` procura a primeira ocorrência da expressão regular em qualquer ponto do texto dado.   \n",
    "Por padrão, a busca diferencia maiúsculas de minúsculas.\n",
    "\n",
    "Assim, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 3), match='The'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'The', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 3), match='The'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(r'The', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... produzem o mesmo resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As funções `re.search()` e `re.match()` ignoram as diferenças entre maiúsculas e minúsculas quando acrescentamos `re.IGNORECASE` ou simplesmente `re.I` ao final da lista de argumentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 3), match='The'>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'the', t, re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 3), match='The'>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(r'the', t, re.I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habitue-se a colocar um ```r``` antes da cadeia que será usada como padrão de busca.   \n",
    "Assim essa cadeia será considerada “bruta” (*raw*) e não será interpretada por Python, o que faz com que barras invertidas (```'\\'```) possam existir na cadeia sem que sejam tratadas como caracteres de escape.   \n",
    "Isso permitirá que a gente escreva coisas como ```'\\w'```, que serão frequentes em nossas expressões regulares, literalmente e não na forma ```'\\\\w'```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padrões Básicos\n",
    "Nos exemplos anteriores buscamos expressões fixas (```'the'``` e ```'The'```) no texto dado.   \n",
    "No entanto, uma grande virtude de expressões regulares é que elas podem especificar padrões variáveis.   \n",
    "\n",
    "Vamos examinar algunns padrões básicos que estabelecem correspondência com caracteres únicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **```a```**, **```X```**, **```9```**   \n",
    "    Caracteres comuns, que devem ser correspondidos exatamente.   \n",
    "    Maiúsculas são consideradas diferentes de minúsculas.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(17, 22), match='quick'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'quick', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **```.```** (ponto)   \n",
    "    Corresponde a qualquer caractere único, exceto “nova linha” (```'\\n'```).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 1), match='T'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'.', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **```\\w```** (w minúsculo)   \n",
    "    Corresponde a qualquer caractere que possa aparecer numa “palavra”: uma letra maiúscula ou minúscula, um dígito decimal ou um “sublinhado”.    \n",
    "    Note que, embora o ```w``` nos remeta a “word”, a correspondência será feita com um único caractere, não com uma uma palavra inteira.   \n",
    "    **```\\W```** (W maiúsculo) corresponde a qualquer caractere não pertencente ao grupo “palavra”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 1), match='T'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'\\w', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(4, 5), match=','>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'\\W', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   \\b\n",
    "    limite entre palavra e não palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 0), match=''>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'\\b', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **```\\s```** (s minúsculo)   \n",
    "Corresponde a um único caractere de espaço em branco: espaço, nova linha (```\\n```), retorno (```\\r```) ou  tabulação (```\\t```).    \n",
    "**```\\S```** (S maiúsculo) corresponde a qualquer caractere que não seja considerado espaço em branco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(5, 6), match=' '>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'\\s', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **```\\t, \\n, \\r```** (tabulação, nova linha, retorno)   \n",
    "Correspondem exatamente a esses caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(35, 36), match='\\n'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'\\n', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **```\\d```** (d minúsculo)   \n",
    "Corresponde a qualquer dígito decimal.   \n",
    "**\\D** (D maiúsculo) corresponde a qualquer caractere que não seja um dígito decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(6, 7), match='8'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'\\d', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **```^```** e **```$```**   \n",
    "    Correspondem, respectivamente, ao início e fim do texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 0), match=''>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'^', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(61, 61), match=''>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'$', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer com que um *metacaractere* se comporte como um caractere normal, insira uma barra invertida na frente dele.   \n",
    "Assim, **```\\.```** corresponde a um “ponto final”,  **```\\\\```** corresponde a uma “barra invertida”, **```\\^```** corresponde a um “circunflexo” e **```\\$```** corresponde a um “cifrão”.\n",
    "\n",
    "Se você ficar em dúvida sobre algum caractere ser ou não um metacaractere, por segurança, coloque uma barra invertida na frente dele.   \n",
    "Assim, por exemplo, **```\\%```** será tratado como **```%```**, seja **```%```** um metacaractere ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(8, 9), match='%'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'\\%', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(8, 9), match='%'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'%', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regras Básicas\n",
    "\n",
    "A satisfação de um critério (definido por uma expressão regular) por uma cadeia de caracteres é verificada de acordo com as seguintes regras básicas:\n",
    "\n",
    "1.   A cadeia de caracteres é examinada da esquerda para a direita.\n",
    "1.   O processo é interrompido assim que a expressão regular bater com um segmento da cadeia de caracteres.\n",
    "1.   Para que o critério seja considerado satisfeito, a expressão regular precisa ter sido inteiramente mapeada sobre a cadeia, mas a cadeia não precisa ter sido totalmente usada.\n",
    "1.   Se na execução de `res = re.search(pad, cad)`, não for encontrada uma correspondência entre a expressão regular `pad` e um trecho da cadeia `cad`, o valor associado a `res` será `None`. \n",
    "Caso contrário, `res != None`, `res.span()` retornará uma tupla com a “*range*” correspondente e`res.group()` retornará o texto encontrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 1. Dada a lista de cadeias de caracteres $cads$, definir um padrão que bata com os dígitos decimais de cada uma delas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'abc123xyz' (3, 6) '123'\n",
      "'123abcxyz' (0, 3) '123'\n",
      "'abcxyz123' (6, 9) '123'\n"
     ]
    }
   ],
   "source": [
    "cads = ['abc123xyz', '123abcxyz', 'abcxyz123']\n",
    "\n",
    "pad = r'123'\n",
    "\n",
    "for cad in cads:\n",
    "    res = re.search(pad, cad)\n",
    "    if res:\n",
    "        print(\"'\" + cad + \"'\", res.span(), \"'\" + res.group() + \"'\")\n",
    "    else:\n",
    "        print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + cad + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'abc123xyz' (3, 6) '123'\n",
      "'456abcxyz' (0, 3) '456'\n",
      "'abcxyz789' (6, 9) '789'\n"
     ]
    }
   ],
   "source": [
    "cads = ['abc123xyz', '456abcxyz', 'abcxyz789']\n",
    "\n",
    "pad = r'\\d\\d\\d'\n",
    "\n",
    "for cad in cads:\n",
    "    res = re.search(pad, cad)\n",
    "    if res:\n",
    "        print(\"'\" + cad + \"'\", res.span(), \"'\" + res.group() + \"'\")\n",
    "    else:\n",
    "        print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + cad + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 2. A lista $cads$ contém cadeias de caracteres variadas mas de mesmo comprimento. Defina um padrão que seja satisfeito pelas três primeiras mas não pela última."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strs = ['abc.', '123.', '-.-.', 'wxyz']\n",
    "\n",
    "pad = r'\\.$'\n",
    "\n",
    "for str in strs:\n",
    "    res = re.search(pad, str)\n",
    "    if res:\n",
    "        print(\"'\" + str + \"'\", res.span(), \"'\" + res.group() + \"'\")\n",
    "    else:\n",
    "        print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + str + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correspondência com conjuntos de caracteres\n",
    "\n",
    "É possível estabelecer correspondência com qualquer caracter de um dado conjunto, especificando este último entre colchetes(**`[`** e **`]`**).   \n",
    "\n",
    "Por exemplo, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'aposta' (2, 3) 'f'\n",
      "'aposta' (0, 1) 'h'\n",
      "'aposta' (1, 2) 'g'\n",
      "a expressão regular '[fgh]' não foi encontrada em 'aposta'\n"
     ]
    }
   ],
   "source": [
    "cads = ['cofre', 'hoje', 'água', 'aposta']\n",
    "\n",
    "pad = r'[fgh]'\n",
    "\n",
    "for cad in cads:\n",
    "    res = re.search(pad, cad)\n",
    "    if res:\n",
    "        print(\"'\" + str + \"'\", res.span(), \"'\" + res.group() + \"'\")\n",
    "    else:\n",
    "        print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + cad + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 3. Dada a lista de cadeias $cads$, criar um padrão que bata com as três primeiras mas não com as três últimas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'aposta' (0, 4) 'tapa'\n",
      "'aposta' (0, 4) 'capa'\n",
      "'aposta' (0, 4) 'papa'\n",
      "a expressão regular '[tcp]apa' não foi encontrada em 'lapa'\n",
      "a expressão regular '[tcp]apa' não foi encontrada em 'mapa'\n",
      "a expressão regular '[tcp]apa' não foi encontrada em 'rapa'\n"
     ]
    }
   ],
   "source": [
    "cads = ['tapa', 'capa', 'papa', 'lapa', 'mapa', 'rapa']\n",
    "\n",
    "pad = r'[tcp]apa'\n",
    "\n",
    "for cad in cads:\n",
    "    res = re.search(pad, cad)\n",
    "    if res:\n",
    "        print(\"'\" + str + \"'\", res.span(), \"'\" + res.group() + \"'\")\n",
    "    else:\n",
    "        print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + cad + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignorar caracteres de um conjunto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível ignorar os caracteres de um dado conjunto colocando-se um **`^`** logo após o colchete que abra o conjunto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 4. Dada a lista de cadeias $cads$, criar um padrão que bata apenas com os nomes de animais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'aposta' (0, 4) 'gato'\n",
      "a expressão regular '[grp]ato' não foi encontrada em 'fato'\n",
      "a expressão regular '[grp]ato' não foi encontrada em 'mato'\n",
      "'aposta' (0, 4) 'rato'\n",
      "a expressão regular '[grp]ato' não foi encontrada em 'tato'\n",
      "'aposta' (0, 4) 'pato'\n"
     ]
    }
   ],
   "source": [
    "cads = ['gato', 'fato', 'mato', 'rato', 'tato', 'pato']\n",
    "\n",
    "pad = r'[grp]ato'\n",
    "\n",
    "for cad in cads:\n",
    "    res = re.search(pad, cad)\n",
    "    if res:\n",
    "        print(\"'\" + str + \"'\", res.span(), \"'\" + res.group() + \"'\")\n",
    "    else:\n",
    "        print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + cad + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'aposta' (0, 4) 'gato'\n",
      "a expressão regular '[^fmt]ato' não foi encontrada em 'fato'\n",
      "a expressão regular '[^fmt]ato' não foi encontrada em 'mato'\n",
      "'aposta' (0, 4) 'rato'\n",
      "a expressão regular '[^fmt]ato' não foi encontrada em 'tato'\n",
      "'aposta' (0, 4) 'pato'\n"
     ]
    }
   ],
   "source": [
    "cads = ['gato', 'fato', 'mato', 'rato', 'tato', 'pato']\n",
    "\n",
    "pad = r'[^fmt]ato'\n",
    "\n",
    "for cad in cads:\n",
    "    res = re.search(pad, cad)\n",
    "    if res:\n",
    "        print(\"'\" + str + \"'\", res.span(), \"'\" + res.group() + \"'\")\n",
    "    else:\n",
    "        print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + cad + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usar faixas de caracteres para especificar conjuntos\n",
    "Ao especificar um conjunto é possível indicar uma sequência contínua de caracteres dando o primeiro e o último elementos separados por um hífen (**`-`**).   \n",
    "Os metacaracteres `\\w`, `\\d` e `\\W` também podem ser usados normalmente neste contexto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 5. Dada a lista de cadeias $cads$, criar um padrão $pad$ que bata com as três primeiras mas não com as três últimas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Ala' (0, 3) 'Ala'\n",
      "'Boa' (0, 3) 'Boa'\n",
      "'Cal' (0, 3) 'Cal'\n",
      "a expressão regular '[A-C][alo][al]' não foi encontrada em 'Mas'\n",
      "a expressão regular '[A-C][alo][al]' não foi encontrada em 'oba'\n",
      "a expressão regular '[A-C][alo][al]' não foi encontrada em 'zip'\n"
     ]
    }
   ],
   "source": [
    "cads = ['Ala', 'Boa', 'Cal', 'Mas', 'oba', 'zip']\n",
    "\n",
    "pad = r'[A-C][alo][al]'\n",
    "\n",
    "for cad in cads:\n",
    "    res = re.search(pad, cad)\n",
    "    if res:\n",
    "        print(\"'\" + cad + \"'\", res.span(), \"'\" + res.group() + \"'\")\n",
    "    else:\n",
    "        print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + cad + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repetições\n",
    "\n",
    "Os padrões que estudamos até aqui batem com caracteres únicos.\n",
    "\n",
    "Para criar um padrão que possa corresponder a um número variável de caracteres, usam-se os metacaracteres **`+`**, **`*`** e **`?`**.\n",
    "-   **`+`** bate com 1 ou mais ocorrências do padrão à sua esquerda\n",
    "-   **`*`** bate com 0 ou mais ocorrências do padrão à sua esquerda\n",
    "-   **`?`** bate com 0 ou 1 ocorrência do padrão à sua esquerda\n",
    "\n",
    "**`+`** e **`*`** buscam na cadeia de caracteres a primeira ocorrência do padrão (isto é, o mais à esquerda possível) e a partir daí tentam usar o maior número possível de caracteres da cadeia.   \n",
    "Esse tipo de correspondência é dito “guloso”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos estudar alguns exemplos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(1, 3), match='ãã'>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ã+ bate com o máximo número de “ã”s começando o mais à esquerda possível\n",
    "re.search(r'ã+', 'Nãão me diga nããããão!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que foi encontrado o conjunto de `ã`s mais à esquerda, que depois foi estendido ao máximo.   \n",
    "Embora mais longo, o segundo grupo de `ã`s não foi considerado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'no mínimo' (0, 2) 'no'\n",
      "'não me diga' (0, 3) 'não'\n",
      "a expressão regular 'nã?o' não foi encontrada em 'agora nãão'\n"
     ]
    }
   ],
   "source": [
    "cads = ['no mínimo', 'não me diga', 'agora nãão']\n",
    "\n",
    "pad = r'nã?o'\n",
    "\n",
    "for cad in cads:\n",
    "    res = re.search(pad, cad)\n",
    "    if res:\n",
    "        print(\"'\" + cad + \"'\", res.span(), \"'\" + res.group() + \"'\")\n",
    "    else:\n",
    "        print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + cad + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, o padrão especificava um “$\\textit{n}$”, seguido por 0 ou 1 “$\\textit{ã}$”, seguido por um “$\\textit{o}$”.    \n",
    "Nas duas primeiras cadeias o padrão foi encontrado, mas na terceira não."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 6. Dada a lista de cadeias $cads$, criar um padrão $pad$ que bata com as três primeiras mas não com a última."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'11133' (0, 5) '11133'\n",
      "'112' (0, 3) '112'\n",
      "'112223' (0, 6) '112223'\n",
      "a expressão regular '11+2*3*' não foi encontrada em '1'\n"
     ]
    }
   ],
   "source": [
    "cads = ['11133', '112', '112223', '1']\n",
    "\n",
    "pad = r'11+2*3*'\n",
    "\n",
    "for cad in cads:\n",
    "    res = re.search(pad, cad)\n",
    "    if res:\n",
    "        print(\"'\" + cad + \"'\", res.span(), \"'\" + res.group() + \"'\")\n",
    "    else:\n",
    "        print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + cad + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitando o número de repetições"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível especificar o número de repetições desejadas de um padrão.\n",
    "-   {$m$} bate com exatamente $m$ repetições do padrão à sua esquerda\n",
    "-   {$m$, $n$} bate com $m$ a $n$ repetições do padrão à sua esquerda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 7. Dada a lista de cadeias $cads$, criar um padrão $pad$ que bata com as duas primeiras mas não com a última."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1233345' (0, 7) '1233345'\n",
      "'123345' (0, 6) '123345'\n",
      "a expressão regular '123{2,3}45' não foi encontrada em '12345'\n"
     ]
    }
   ],
   "source": [
    "cads = ['1233345', '123345', '12345']\n",
    "\n",
    "pad = r'123{2,3}45'\n",
    "\n",
    "for cad in cads:\n",
    "    res = re.search(pad, cad)\n",
    "    if res:\n",
    "        print(\"'\" + cad + \"'\", res.span(), \"'\" + res.group() + \"'\")\n",
    "    else:\n",
    "        print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + cad + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 8. Dada a lista de cadeias $cads$, criar um padrão $pad$ que bata com as três primeiras mas não com as duas últimas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'112233' (0, 6) '112233'\n",
      "'11122233' (0, 8) '11122233'\n",
      "'111222333' (0, 9) '111222333'\n",
      "a expressão regular '1{2,3}2{2,3}3{2,3}' não foi encontrada em '1223'\n",
      "a expressão regular '1{2,3}2{2,3}3{2,3}' não foi encontrada em '1233'\n"
     ]
    }
   ],
   "source": [
    "cads = ['112233', '11122233', '111222333', '1223', '1233']\n",
    "\n",
    "pad = r'1{2,3}2{2,3}3{2,3}'\n",
    "\n",
    "for cad in cads:\n",
    "    res = re.search(pad, cad)\n",
    "    if res:\n",
    "        print(\"'\" + cad + \"'\", res.span(), \"'\" + res.group() + \"'\")\n",
    "    else:\n",
    "        print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + cad + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'112233' == '112233': True\n",
      "'11122233' == '11122233': True\n",
      "'111222333' == '111222333': True\n",
      "a expressão regular '1{2,3}2{2,3}3{2,3}' não foi encontrada em '1223'\n",
      "a expressão regular '1{2,3}2{2,3}3{2,3}' não foi encontrada em '1233'\n"
     ]
    }
   ],
   "source": [
    "cads = ['112233', '11122233', '111222333', '1223', '1233']\n",
    "\n",
    "pad = r'1{2,3}2{2,3}3{2,3}'\n",
    "\n",
    "for cad in cads:\n",
    "    res = re.search(pad, cad)\n",
    "    if res:\n",
    "        print(\"'\" + cad + \"' == '\" + res.group() + \"':\", cad == res.group())\n",
    "    else:\n",
    "        print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + cad + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 9. Dada a lista de cadeias $cads$, criar um padrão $pad$ que extraia o endereço de e-mail contido em cada uma delas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice@themail.com\n",
      "maria@themail.com.br\n",
      "maria.123@mymail.com\n",
      "jose-silva@mymail.com.br\n"
     ]
    }
   ],
   "source": [
    "cads = ['blá blá blá alice@themail.com', \n",
    "        'abc xyz maria@themail.com.br etc etc', \n",
    "        'abc xyz maria.123@mymail.com blá blá', \n",
    "        'jose-silva@mymail.com.br'\n",
    "       ]\n",
    "\n",
    "pad = r'[\\w.-]+@\\w+(\\.\\w+)+'\n",
    "\n",
    "for cad in cads:\n",
    "    res = re.search(pad, cad)\n",
    "    if res:\n",
    "        print(res.group())\n",
    "    else:\n",
    "        print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + cad + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração de Grupos\n",
    "Em uma expressão regular, “grupos” permitem separar algumas partes do texto correspondente.   \n",
    "\n",
    "Suponha que, no exemplo anterior, queiramos extrair o nome do usuário e do serviço hospedeiro separadamente.   \n",
    "Para isso, colocamos o nome de usuário e o do hospedeiro entre parênteses, como mostrado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = r'([\\w.-]+)@(\\w+(\\.\\w+)+)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os parênteses não alteram a funcionalidade do padrão, mas estabelecem “grupos lógicos” dentro do texto de correspondência.   \n",
    "Se a busca for bem-sucedida, `res.group(1)` restornará o texto correspondente ao primeiro par de parênteses e `res.group(2)` retornará o texto correspondente ao segundo par.    \n",
    "A chamada `res.group()` continuará retornando todo o texto mapeado como de costume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice        themail.com        alice@themail.com             \n",
      "maria        themail.com.br     maria@themail.com.br          \n",
      "maria.123    mymail.com         maria.123@mymail.com          \n",
      "jose-silva   mymail.com.br      jose-silva@mymail.com.br      \n"
     ]
    }
   ],
   "source": [
    "for cad in cads:\n",
    "    res = re.search(pad, cad)\n",
    "    if res:\n",
    "        print(f\"{res.group(1):12} {res.group(2):18} {res.group():30}\")\n",
    "    else:\n",
    "        print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + cad + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrando múltiplas ocorrências de um padrão\n",
    "A função `re.findall()` é semelhante a `re.search()` mas retorna uma lista com todas as sub-cadeias que satisfazem o padrão na cadeia dada.   \n",
    "Por exemplo, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice@themail.com\n",
      "maria@themail.com.br\n",
      "maria.123@mymail.com\n",
      "jose-silva@mymail.com.br\n"
     ]
    }
   ],
   "source": [
    "cad = ''' blá blá blá alice@themail.com     abc xyz maria@themail.com.br etc etc \n",
    "          abc xyz maria.123@mymail.com blá blá jose-silva@mymail.com.br\n",
    "      '''\n",
    "\n",
    "pad =  r'[\\w\\.-]+@[\\w\\.-]+'\n",
    "\n",
    "res = re.findall(pad, cad)\n",
    "if res:\n",
    "    for r in res:\n",
    "        print(r)\n",
    "else:\n",
    "    print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + cad + \"'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se usarmos grupos na definição do padrão, `re.findall()` retornará uma lista de tuplas, cujos elementos corresponderão aos grupos do padrão.\n",
    "Por exemplo, podemos separar o nome do usuário e o nome do hospedeiro, como num exemplo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice        themail.com        ('alice', 'themail.com')\n",
      "maria        themail.com.br     ('maria', 'themail.com.br')\n",
      "maria.123    mymail.com         ('maria.123', 'mymail.com')\n",
      "jose-silva   mymail.com.br      ('jose-silva', 'mymail.com.br')\n"
     ]
    }
   ],
   "source": [
    "cad = ''' blá blá blá alice@themail.com     abc xyz maria@themail.com.br etc etc \n",
    "          abc xyz maria.123@mymail.com blá blá jose-silva@mymail.com.br\n",
    "      '''\n",
    "\n",
    "pad =  r'([\\w\\.-]+)@([\\w\\.-]+)'\n",
    "\n",
    "res = re.findall(pad, cad)\n",
    "if res:\n",
    "    for r in res:\n",
    "        print(f'{r[0]:12} {r[1]:18} {r}')\n",
    "else:\n",
    "    print('a expressão regular', \"'\" + pad + \"'\", 'não foi encontrada em', \"'\" + cad + \"'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrando múltiplas ocorrências de um padrão com um iterador\n",
    "Quando o texto a ser examinado é muito grande, como um arquivo, por exemplo, pode não ser interessante localizar todas as ocorrências de um padrão  antes de começar a processá-las.   \n",
    "Um *iterador* produz o mesmo efeito mas gera seus elementos um a um, na medida do necessário.   \n",
    "Isto pode ser muito vantajoso em termos de tempo e espaço.\n",
    "\n",
    "No exemplo abaixo, usamos `re.finditer()` para localizar e separar os nomes dos usuários e dos hospedeiros do exemplo anterior.   \n",
    "Note a diferença na posição dos elementos nas tuplas resultantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice@themail.com              alice        themail.com       \n",
      "maria@themail.com.br           maria        themail.com.br    \n",
      "maria.123@mymail.com           maria.123    mymail.com        \n",
      "jose-silva@mymail.com.br       jose-silva   mymail.com.br     \n"
     ]
    }
   ],
   "source": [
    "cad = ''' blá blá blá alice@themail.com     abc xyz maria@themail.com.br etc etc \n",
    "          abc xyz maria.123@mymail.com blá blá jose-silva@mymail.com.br\n",
    "      '''\n",
    "\n",
    "pad =  r'([\\w\\.-]+)@([\\w\\.-]+)'\n",
    "\n",
    "res = re.finditer(pad, cad)\n",
    "for r in res:\n",
    "    print(f'{r[0]:30} {r[1]:12} {r[2]:18}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substituição do padrão nas ocorrências localizadas\n",
    "A função `re.sub()` permite substituir todas as ocorrências do padrão localizadas no texto original por uma nova cadeia.   \n",
    "A cadeia de substituição pode incluir `\\1`, `\\2`,... para se referir a `group(1)`, `group(2)`,... do padrão.\n",
    "\n",
    "Por exemplo, vamos substituir o hospedeiro por `newmail.com` em todos os endereços de e-mail localizados no exemplo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " blá blá blá alice@newmail.com     abc xyz maria@newmail.com etc etc \n",
      "          abc xyz maria.123@newmail.com blá blá jose-silva@newmail.com\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "cad = ''' blá blá blá alice@themail.com     abc xyz maria@themail.com.br etc etc \n",
    "          abc xyz maria.123@mymail.com blá blá jose-silva@mymail.com.br\n",
    "      '''\n",
    "\n",
    "pad =  r'([\\w\\.-]+)@([\\w\\.-]+)'\n",
    "scad = r'\\1@newmail.com'\n",
    "\n",
    "res = re.sub(pad, scad, cad)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy and lazy matching\n",
    "Let's try to get the \"day\" portion of each date. It is the first and only captured group in this pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fi = finditer(r'(?x) / (.* ) /', t)\n",
    "\n",
    "[m.group(1) for m in fi]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What went wrong? By default, **\\*** is greedy.  We can make it lazy by adding **?**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fi = finditer(r'(?x) / (.*? ) /', t)\n",
    "\n",
    "[m.group(1) for m in fi]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works for the other quantifiers as well.  (**+, ?, {m,n}**)\n",
    "\n",
    "This one is eager and has an internal **e** in the first match and an internal **o** in the second match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fi = finditer(r'(?x) ([aeiou]) .* \\1', t)\n",
    "\n",
    "[m.group(0) for m in fi]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is lazy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fi = finditer(r'(?x) ([aeiou]) .*? \\1', t)\n",
    "\n",
    "[m.group(0) for m in fi]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split\n",
    "**split** works differently in **regex**.  Let's start with **re**.\n",
    "This is a familiar split on whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'\\s+', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this splits on the letter **o**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'o', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a gotcha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'o', t, IGNORECASE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third argument to **split** does not give options.  It gives the maximum number of splits.  We unknowingly specified 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IGNORECASE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For split, it is better to use **(?i)** for case-insensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'(?i)the', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can use the **flags** keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'the', t, flags=IGNORECASE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing in the pattern for **split**\n",
    "\n",
    "This one splits on words with an internal **u**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'\\w+u\\w+', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we wanted to save the **u**-words?  We can use parentheses to capture things inside the splitting pattern!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'(\\w+u\\w+)', t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'\\w*o\\w*', t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'(\\w*o\\w*)', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split on 4-letter words.  Then we do it again and capture the 4-letter words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'\\b\\w{4}\\b', t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'\\b(\\w{4})\\b', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **split** and zero-width assertions.\n",
    "Here we split on word boundaries.  **\\\\b** is a zero-width assertion.  It requires that certain characters be present, but it doesn't \"consume\" them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'\\b',t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what went wrong?  Unlike **split** in Perl, the split function in **re** will not split on zero-width assertions. The new **regex** module gets this right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from regex import *\n",
    "split(r'\\b',t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops. To get the new behavior, we must add the \"Version 1\" option to the regular expression.  \"Version 0\" emulates **re**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split(r'(?V1)\\b',t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make life a little easier by setting the version globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "regex.DEFAULT_VERSION = VERSION1\n",
    "split(r'\\b',t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\\\\m** and **\\\\M** are zero-width assertions that are true at the beginnings and ends of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'\\M',t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'\\m',t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look-arounds\n",
    "We can split on any 4-letter word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'(?x) \\b \\w{4} \\b', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we want to split on any 4-letter word but **born**? We can use a look-ahead assertion.  Look-aheads and look-behinds come in two flavors: positive and negative.  All four are zero-width assertions.  They required certain characters to be present or absent, but don't consume the characters.  In this case, we need a negative assertion.  We could do a look-ahead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'(?x) \\b (?!born) \\w{4} \\b', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or a look-behind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'(?x) \\b \\w{4} (?<!born) \\b', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or, if we are feeling perverse, both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'(?x) \\b (?!bor) \\w{4} (?<!orn) \\b', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one splits on any 4-letter word that doesn't contain **o**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'(?x) \\b (?!\\w*o) \\w{4} \\b', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one splits on the letter **o**.  The **o** is consumed and lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'(?x) o', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one has a positive look-ahead assertion.  It splits before every **o**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'(?x) (?=o)', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one has a positive look-behind assertion.  It splits after evey **o**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'(?x) (?<=o)', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one splits between  **o** and **r**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'(?x) (?<=o) (?=r)', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assertions could appear in either order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'(?x) (?=r) (?<=o)', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one splits between any two consecutive vowels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(r'(?x) (?<=[aeiou]) (?=[aeiou])', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun with DNA: Open reading frames\n",
    "DNA is a sequence of bases, A, C, G, or T.  They are translated into proteins 3 bases at a time.  Each 3-base sequence is called a **codon**.  There is a special **start codon** ATG, and three **stop codons**, TGA, TAG, and TAA.  The start and stop codons are highlighted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dna = 'cgcgcATGcgcgcgTGAcgcgcgTAGcgcgcgcgc'\n",
    "\n",
    "dna = dna.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An **opening reading frame** or **ORF** consists of a start codon, followed by some more codons, and ending with a stop codon.  (In real life, \"some more\" is usually hundreds or thousands.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orfpat = r'(?x) atg (...)* (tga|tag|taa)'\n",
    "\n",
    "search(orfpat,dna)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, that's not quite right.  The internal codons should not be stop codons. We can handle that with a negative lookahead assertion.  (Can you think of another way?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orfpat = r'(?x) atg  ( (?!tga|tag|taa) ... )*  (tga|tag|taa)'\n",
    "\n",
    "search(orfpat,dna)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't really want to capture the \"some more codons\" separately.  In a minute that will get in the way.  So we can use **(?:...)** to group without capturing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orfpat = r'(?x) ( atg  (?: (?!tga|tag|taa) ... )*  (?:tga|tag|taa) )'\n",
    "\n",
    "findall(orfpat,dna)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another DNA sequence.  Note that this one has overlapping ORFs.  We would like a list of **all** orfs, specifically **ATGcATGcgTGA** and **ATGcgTGAcTAA**.  Our last pattern only finds the first ORF. Since it consumes the first ORF, it also consumes the beginning of the second ORF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dna = 'cgcgcATGcATGcgTGAcTAAcgTAGcgcgcgcgc'\n",
    "\n",
    "dna = dna.lower()\n",
    "\n",
    "findall(orfpat,dna)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to find something without consuming it, we can use a positive lookahead assertion.  We put the whole ORF pattern inside the lookahead.  We need to capture what is matched by the lookahead without consuming it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orfpat = r'(?x) (?= ( atg  (?: (?!tga|tag|taa) ... )*  (?:tga|tag|taa) ))'\n",
    "\n",
    "findall(orfpat,dna)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the position of the capturing parentheses.  This doesn't work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orfpat = r'(?x) ( (?= atg  (?: (?!tga|tag|taa) ... )*  (?:tga|tag|taa) ))'\n",
    "\n",
    "findall(orfpat,dna)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why? Because the look-ahead assertion has width 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More fun with DNA: Restriction Digest Assays\n",
    "To perform certain assays, molecular biologists subject DNA sequences to enzymes known as restriction enzymes. There are several types; this is about Type II restriction endonucleases, to be precise. They are usually named with three letters, for the species of origin, and a Roman numeral; e.g., AfeI comes from Alcaligenes faecalis.  These enzymes typically recognize a specific sequence of 6-10 letters, and cut the DNA somewhere in the middle of that sequence.  For example, BgIII recognizes **AGATCT** and cuts between the first **A** and the **G**.\n",
    "\n",
    "For a typical assay, the DNA will be digested by a \"cocktail\" of 3-6 enzymes. The lengths of the resulting pieces will be measured by gel electrophoresis.  The lengths should match up with the lengths predicted by an in silico digestion. If not, something is wrong.\n",
    "Our task is to do the in silico digestion.\n",
    "\n",
    "For development, here is a dictionary of 4 enzymes, a DNA sequence to digest, and the string we would like to get out of the process. In real life, the DNA sequence would be thousands to ten-thousands of letters long. The researcher could be interested in knowing the cut-points for dozens of enzymes, even though a typical assay uses just a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enzymes = {'A-GATCT': 'BgIII',\n",
    "           'AGC-GCT': 'AfeI',\n",
    "           'AGG-CCT': 'StuI',\n",
    "           'AT-CGAT': 'ClaI'}\n",
    "\n",
    "dna = 'AAAAGCGCTAAAATCGATAAAAAAGATCTAAAAAGCGCT'\n",
    "\n",
    "goal = 'AAAAGC <AfeI> GCTAAAAT <ClaI> CGATAAAAAA <BgIII> GATCTAAAAAGC <AfeI> GCT'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use positive look-aheads and look-behinds.  We will build a look ahead-look behind combination for each enzyme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pats = ['(?<=' + fore + ')(?=' + aft + ')' \n",
    "        \n",
    "        for (fore,aft) in [split(r'-',s) for s in enzymes.keys()]]\n",
    "\n",
    "pats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pats = ' | '.join(pats)\n",
    "pats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pat = \"(?x) ( \" + pats + \" )\"\n",
    "pat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(goal)\n",
    "\n",
    "split(pat,dna)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a good start.  We split in the right places, but we didn't capture the recognition sequences, so we can't retrieve the name of the enzyme from the dictionary. In fact, we captured empty strings.  That's because we captured a zero-width assertion. So we will add some parentheses to capture the look-aheads and look-behinds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pats = ['(?<=(' + fore + ')) (?=(' + aft + '))' \n",
    "        \n",
    "        for (fore,aft) in [split(r'-',s) for s in enzymes.keys()]]\n",
    "\n",
    "pats = '  |  '.join(pats)\n",
    "pat = '(?x) (?: ' + pats + ' )'\n",
    "pat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(pat,dna)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened?  The pattern has eight sets of capturing parentheses. So, the match also returns eight groups when it's executed.  Only the parentheses from the successful alternative will capture anything.  The other six groups are set to **None**.\n",
    "\n",
    "Happily, **regex** provides a new \"branch reset\" feature. Briefly, it means that capturing occurs only on the successful branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pat = '(?x) (?| ' + pats + ' )'\n",
    "pat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split(pat,dna)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray!  Now all we have to do it to map the recognition sequences into enzyme names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "L = split(pat,dna)\n",
    "\n",
    "LL = [ ' <' + enzymes[L[i]+'-'+L[i+1]] + '> '+ L[i+2] \n",
    "      \n",
    "                  for i in range(1,len(L),3) ]\n",
    "\n",
    "L[0] + ''.join(LL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can pull it all together into a nice class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import regex as re\n",
    "\n",
    "class EndonucleaseDigestor:\n",
    "    \n",
    "    def __init__(this,enzymeDict):\n",
    "        pats = ['(?<=(' + fore + '))(?=(' + aft + '))' \n",
    "                for (fore,aft) in [re.split(r'-',s) for s in enzymeDict.keys()]]\n",
    "        pat = ' | '.join(pats)\n",
    "        pat = '(?x) (?| ' + pat + ' )'\n",
    "        this.pat = re.compile(pat)\n",
    "        this.enzymes = enzymeDict\n",
    "        \n",
    "    def digest(this,dna):\n",
    "        L = this.pat.split(dna)\n",
    "        LL = [ ' <' + enzymes[L[i]+'-'+L[i+1]] + '> '+ L[i+2] for i in range(1,len(L),3) ]\n",
    "        return L[0] + ''.join(LL)\n",
    "        \n",
    "\n",
    "enzymes = {'A-GATCT': 'BgIII',\n",
    "           'AGC-GCT': 'AfeI',\n",
    "           'AGG-CCT': 'StuI',\n",
    "           'AT-CGAT': 'ClaI'}\n",
    "dna = 'AAAAGCGCTAAAATCGATAAAAAAGATCTAAAAAGCGCT'\n",
    "goal = 'AAAAGC <AfeI> GCTAAAAT <ClaI> CGATAAAAAA <BgIII> GATCTAAAAAGC <AfeI> GCT'\n",
    "\n",
    "digestor = EndonucleaseDigestor(enzymes)\n",
    "if digestor.digest(dna) == goal: print(\"passed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TMTOWTDT: **sub** with a function\n",
    "There's another way to solve the restriction digest problem. This time let's start by building a dictionary that maps the recognition sequences into versions with the enzyme name interposed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = { sub('-','',k) : sub('-',\" <\"+v+\"> \", k) for k,v in enzymes.items()}\n",
    "d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's build a pattern that matches all the recognition sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p = ' | '.join( [ sub('-','',k) for k in enzymes.keys()])\n",
    "p = '(?x) (' + p + ')'\n",
    "p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second argument to **sub** can be a function rather than a string.  If so, the function is called with a **match** object as its argument.  We are interested in the first (and only) thing captured in the match and we want to get the corresponding string out of dictionary **d**.  So we define a function to do that.  Then we call sub with that function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def subber (m):\n",
    "    print(m)\n",
    "    return d[m.group(1)]\n",
    "\n",
    "sub(p, subber, dna)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can make a class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import regex as re\n",
    "\n",
    "class AnotherEndonucleaseDigestor:\n",
    "    \n",
    "    def __init__(this,enzymeDict):\n",
    "        this.d = { re.sub('-','',k) : re.sub('-',\" <\"+v+\"> \", k) for k,v in enzymes.items()}\n",
    "        p = ' | '.join( [ re.sub('-','',k) for k in enzymes.keys()])\n",
    "        p = '(?x) (' + p + ')'\n",
    "        this.pat = re.compile(p)\n",
    "        this.enzymes = enzymeDict\n",
    "        \n",
    "    def digest(this,dna):\n",
    "        return this.pat.sub( lambda m: this.d[m.group(1)]  , dna)\n",
    "\n",
    "enzymes = {'A-GATCT': 'BgIII',\n",
    "           'AGC-GCT': 'AfeI',\n",
    "           'AGG-CCT': 'StuI',\n",
    "           'AT-CGAT': 'ClaI'}\n",
    "dna = 'AAAAGCGCTAAAATCGATAAAAAAGATCTAAAAAGCGCT'\n",
    "goal = 'AAAAGC <AfeI> GCTAAAAT <ClaI> CGATAAAAAA <BgIII> GATCTAAAAAGC <AfeI> GCT'\n",
    "\n",
    "digestor = AnotherEndonucleaseDigestor(enzymes)\n",
    "if digestor.digest(dna) == goal: print(\"passed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That probably seems a lot simpler, but there is one problem.  What if two recognition sites are overlapping?  For the in silico simulation of a real digest, it doesn't much matter, because the resolution of gel electrophoresis is much less than the 5-10 bases that might be overlapping.  On the other hand, if the scientist actually wants a complete inventory of all the restriction sites for a large set of enzymes, overlaps matter, and this solution won't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested sets\n",
    "We have seen some character sets such as **[aeiou]** for all (lower-case) vowels.  Suppose we want all lower-case consonants.  One obvious way is to list them all.  We might also be tempted to use set negation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "findall(r'[^aeiou]+',t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that we get not just consonants, but spaces, digits, etc.\n",
    "The new **regex** module allows us to do arithmetic on sets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "findall(r'(?x) [[a-z]--[aeiou]]+', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy matching\n",
    "With **regex**, you can specify that patterns need only be satisfied approximately.  You can specify the number of insertions (**i**), number of deletions (**d**), and number of substitutions (**s**) as well as total number of errors (**e**).\n",
    "This example allows at most one insertion and at most one deletion for each pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(finditer(r'(brown|lazy){i<=1,d<=1} (dog|fox){i<=1,d<=1}',\n",
    "              \n",
    "              'The quick crown fax barn on Monday jumped over the sleazy hog bran on Tuesday.'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the match object reports the number of insertions, deletions, and substitutions as **fuzzy_counts**. \n",
    "\n",
    "You can even **require** a minimum number of errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(finditer(r'(brown|lazy){1<=e<=3} (dog|fox){1<=e<=2}',\n",
    "                            \n",
    "              'The quick crown fax barn on Monday jumped over the sleazy hog bran on Tuesday.'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What matched what?  We can find out by doing some more capturing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "findall(r'(?:(brown)|(lazy)){1<=e<=3} (?:(dog)|(fox)){1<=e<=2}',\n",
    "        \n",
    "        'The quick crown fax barn on Monday jumped over the sleazy hog bran on Tuesday.')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we try our orginal correct string? We should get back no matches, because there are no errors, right?  Maybe not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "findall(r'(?:(brown)|(lazy)){1<=e<=3} (?:(dog)|(fox)){1<=e<=2}',\n",
    "        \n",
    "        'The quick brown fox born on 1/23/2013 jumped over the lazy dog born on 10/6/10.')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe it will work if we try the **BESTMATCH** option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "findall(r'(brown|lazy){1<=e<=3} (dog|fox){1<=e<=2}',\n",
    "        'The quick brown fox born on 1/23/2013 jumped over the lazy dog born on 10/6/10.',\n",
    "        BESTMATCH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm.  Maybe we need the **ENHANCEMATCH** option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "findall(r'(brown|lazy){1<=e<=3} (dog|fox){1<=e<=2}',\n",
    "        'The quick brown fox born on 1/23/2013 jumped over the lazy dog born on 10/6/10.',\n",
    "         ENHANCEMATCH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we should use both...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "findall(r'(brown|lazy){1<=e<=3} (dog|fox){1<=e<=2}',\n",
    "        'The quick brown fox born on 1/23/2013 jumped over the lazy dog born on 10/6/10.',\n",
    "         ENHANCEMATCH | BESTMATCH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now let's try a spelling corrector.  Here's a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('words.txt')\n",
    "\n",
    "f.readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = f.readlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words =  ' '.join( [sub('\\n', '', w) for w in words] )\n",
    "words[-60:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a string with some misspelled (and correct) words. It might seem counterintuitive, but we will take the misspelled words and turn them into a pattern, and use the dictionary as the target sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "misspelt = 'abrogatting baandoned abreviat astracted absinthe abussed abus zoan'\n",
    "\n",
    "misspelt = split('\\W+', misspelt)\n",
    "\n",
    "misspelt = [r\"(\" + s + r\"){e<=2}\" for s in misspelt]\n",
    "\n",
    "misspelt = r\"(?x) \\m (?: \" + \" | \".join(misspelt) + r\" ) \\M\"\n",
    "\n",
    "misspelt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this time we did not use the brach reset feature.  That's because the captured empty strings are going to tell us which misspelled word was matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lis = findall(misspelt,words, ENHANCEMATCH)\n",
    "\n",
    "lis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will transpose the matrix.  Every column will contain matches for a single misspelled word.  Most of the entries will be empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z = list(zip(*lis))\n",
    "\n",
    "z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can filter out the empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z = [ list(filter(lambda s: s!= '', L)) for L in z]\n",
    "\n",
    "z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not entirely satisfactory, but it might work well for correcting the spelling of small sets of words, for example, state names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple captures\n",
    "It's now possible to obtain information on all the successful matches of a repeated capture group, not just the last one.  Use **captures** instead of **group**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dna = 'cgcgcATGcgcattcgggcgTGAcgcgcgTAGcgcgcgcgc'\n",
    "dna = dna.lower()\n",
    "\n",
    "orfpat = r'(?x) (?= ( atg  ( (?!tga|tag|taa) ... )*  (?:tga|tag|taa) ))'\n",
    "\n",
    "search(orfpat,dna).captures(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search(orfpat,dna).captures(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also capture things by name.  The string **s** is an excerpt of a long file describing a gene network.  Each line contains two gene names, and the strength of the connection between them.  In this example, we are only interested in gathering the gene names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = \"\"\"AT1G01280\tAT1G01450\t5.1E-3\n",
    "AT1G01480\tAT1G01560\t2.3E-2\n",
    "AT1G01600\tAT1G01610\t1.6E-2\n",
    "AT1G01430\tAT1G01630\t2.1E-2\n",
    "AT1G01150\tAT1G01700\t1.1E-2\n",
    "\"\"\"\n",
    "\n",
    "m = match(\n",
    "    r'(?x) (?: (?P<geneA>\\w+) \\s+ (?P<geneB>\\w+) \\s+ \\S+ \\n )*',\n",
    "    s)\n",
    "\n",
    "m.capturesdict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even reuse a name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = match(\n",
    "    r'(?x) (?: (?P<gene>\\w+) \\s+ (?P<gene>\\w+) \\s+ \\S+ \\n )*',\n",
    "    s)\n",
    "\n",
    "m.capturesdict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(set(m.capturesdict()['gene']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse searching\n",
    "\n",
    "Searches can now work backwards:\n",
    "\n",
    "Note: the result of a reverse search is not necessarily the reverse of a forward search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "findall(r\"(?r)..\", \"abcde\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who cares?  I thought of an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub(r'(?rx) (\\d\\d\\d)',\n",
    "    r',\\1',\n",
    "    '1 mile = 1760 yards = 5280 ft = 63360 in = 1609344 mm = 160934.4 cm, more or less.  Pi = 3.14159')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub(r'(?rx)  (?<=\\d) (\\d\\d\\d)',\n",
    "    r',\\1',\n",
    "    '1 mile = 1760 yards = 5280 ft = 63360 in = 1609344 mm = 160934.4 cm, more or less.  Pi = 3.14159')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub(r'(?rx)  (?<! [.] \\d*) (?<=\\d) (\\d\\d\\d)',\n",
    "    r',\\1',\n",
    "    '1 mile = 1760 yards = 5280 ft = 63360 in = 1609344 mm = 160934.4 cm, more or less.  Pi = 3.14159')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POSIX Matching (Leftmost Longest)\n",
    "\n",
    "The default matching method for alternations is to match the first alternative that will match. The POSIX standard is to find the leftmost longest match. This can be turned on using the POSIX flag **(?p)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(finditer( r'(dog|doge|doggerel)', 'The doge wrote nothing but doggerel.'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(finditer( r'(?p)(dog|doge|doggerel)', 'The doge wrote nothing but doggerel.'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **fullmatch**\n",
    "The pattern must match the entire string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match(r'The doge', 'The doge wrote nothing but doggerel.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fullmatch(r'The doge', 'The doge wrote nothing but doggerel.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope, that one didn't match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial matching\n",
    "Can the target string be extended to match the pattern?  The optional **partial** argument to **match**, **search**, and **fullmatch** can answer this question. This could be useful if you are validating input from the terminal, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is true, because the target can be extended to 'The doge wrote nothing but doggerel.' to match the pattern.  But, if you think about it, you will see that this one is true for any target string.  (It can be extended with 'dogdog'.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fullmatch(r'.*dog.*dog.*', 'The doge wrote nothing', partial=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is more interesting: Can the string be extended to be a Social Security Number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fullmatch(r'\\d\\d\\d-\\d\\d-\\d\\d\\d\\d',  \"999-89-7\", partial=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match(r'\\d\\d\\d-\\d\\d-\\d\\d\\d\\d',  \"999-89-7\", partial=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fullmatch(r'\\d\\d\\d-\\d\\d-\\d\\d\\d\\d',  \"My SSN is 999-89-7\", partial=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match(r'\\d\\d\\d-\\d\\d-\\d\\d\\d\\d',  \"My SSN is 999-89-7\", partial=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search(r'\\d\\d\\d-\\d\\d-\\d\\d\\d\\d',  \"My SSN is 999-89-7\", partial=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this one is a complete match, so the **partial** field is missing from the match object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search(r'\\d\\d\\d-\\d\\d-\\d\\d\\d\\d',  \"My SSN is 999-89-7654, but don't tell.\", partial=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search(r'\\d\\d\\d-\\d\\d-\\d\\d\\d\\d',  \"My SSN is 999-89-76, but don't tell.\", partial=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some functional programming fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def twice(f):\n",
    "    return lambda x: f(f(x))\n",
    "\n",
    "def prepender(s):\n",
    "    return lambda t: s + t\n",
    "\n",
    "twice(twice)(twice(prepender('spam ')))('eggs and spam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "twice(twice)(twice(prepender(len('spam '))))(len('eggs and spam'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark's puzzle\n",
    "Which character is most frequent in a string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most(s, care_about=r'\\w'):\n",
    "    t=''.join(sorted(s))\n",
    "    p = r'((' + care_about + r')\\2*)'\n",
    "    L = [ m.group(1) for m in finditer(p, t) ]\n",
    "    m = max(L, key=len)\n",
    "    return (m[0], len(m))\n",
    "\n",
    "most('123462232340997092')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most('123462232340997092', care_about='[13579]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most(twice(twice)(twice(prepender('spam ')))('eggs and spam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most(twice(twice)(twice(prepender('spam ')))('eggs and spam'), r'[^aeiou\\s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
